{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Training data already downloaded\nTest data already downloaded\n"
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "try:\n",
    "    with open(\"in.dta\", \"x\") as f_in:\n",
    "        request_in = requests.get(\"http://work.caltech.edu/data/in.dta\")\n",
    "        f_in.write(request_in.text)\n",
    "except FileExistsError as e:\n",
    "    print(\"Training data already downloaded\")\n",
    "\n",
    "try:\n",
    "    with open(\"out.dta\",\"x\") as f_out:\n",
    "        request_out = requests.get(\"http://work.caltech.edu/data/out.dta\")\n",
    "        f_out.write(request_out.text)\n",
    "except FileExistsError as e:\n",
    "    print(\"Test data already downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " class Dataset:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "        self.line_num = None\n",
    "\n",
    "    def read_data(self, location):\n",
    "\n",
    "        with open(location) as data_in:\n",
    "            line_num = 0\n",
    "            self.X, self.Y = [], []\n",
    "            for line in data_in:\n",
    "                line = list(map(float, line.strip().split()))\n",
    "                # default value for spliting is any white space\n",
    "                # rstrip strip right space, lstrip strip left space, strip does both\n",
    "                x = np.array([1, line[0], line[1]])\n",
    "                x = self.transformation(x)\n",
    "                y = np.array(line[2])\n",
    "                \n",
    "                self.X.append(x)\n",
    "                self.Y.append(y)\n",
    "                \n",
    "                line_num += 1\n",
    "\n",
    "            self.line_num = line_num\n",
    "            self.X, self.Y = np.array(self.X), np.array(self.Y)\n",
    "            return self.X, self.Y\n",
    "    \n",
    "    def transformation(self, x):\n",
    "        return np.array([x[0], x[1], x[2], x[1]**2, x[2]**2, x[1]*x[2], abs(x[1]-x[2]), abs(x[1]+x[2])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.weight = None\n",
    "    \n",
    "    def training(self, dataset,k): # minimising Error in, Ein\n",
    "        dataset.read_data(\"in.dta\")\n",
    "        transpose_X = np.transpose(dataset.X)\n",
    "        inverse_XTX = np.linalg.pinv(transpose_X @ dataset.X + (10**k) * np.identity(8))\n",
    "        peusdo_inverse = inverse_XTX @ transpose_X\n",
    "        self.weight = peusdo_inverse @ dataset.Y\n",
    "\n",
    "        return self.weight\n",
    "\n",
    "    def testing(self, error_total, dataset, insample = True): \n",
    "\n",
    "        # Generate new data if testing outsample error\n",
    "        if (insample): dataset.read_data(\"in.dta\")\n",
    "        if (not insample): dataset.read_data(\"out.dta\")\n",
    "\n",
    "        # testing using square error\n",
    "        # square_error = np.transpose(dataset.X @ self.weight - dataset.Y) @ (dataset.X @ self.weight - dataset.Y) # not really square error\n",
    "        # print(square_error)\n",
    "        # square_error = 1/dataset.line_num * square_error # @ means matrix multiplication\n",
    "        # error_total += square_error\n",
    "\n",
    "        # testing using classification error\n",
    "        prediction = np.sign(dataset.X @ self.weight) # the position in dot or @ product matters\n",
    "        actual_value = np.array(dataset.Y)\n",
    "        if (not insample): classification_error = sum(prediction != actual_value)/dataset.line_num\n",
    "        elif(insample): classification_error = (sum(prediction != actual_value))/dataset.line_num\n",
    "        error_total += classification_error\n",
    "        return error_total\n",
    "\n",
    "    def main(self):\n",
    "        dataset_ = Dataset()\n",
    "        k_range = range(-5,5)\n",
    "        print(k_range)\n",
    "        for k in k_range:\n",
    "            error_insample_total = 0\n",
    "            error_outsample_total = 0\n",
    "            _ = self.training(dataset_,k)\n",
    "            error_insample_total = self.testing(error_insample_total, dataset_, True)\n",
    "            error_outsample_total = self.testing(error_outsample_total, dataset_, False)\n",
    "            print(k)\n",
    "            print(error_insample_total)\n",
    "            print(error_outsample_total)\n",
    "\n",
    "        return error_insample_total, error_outsample_total, self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.02857142857142857\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(3.4857142857142853,\n 4.42,\n array([ 4.99999930e-09, -1.36334506e-09,  2.59967566e-09,  3.56447526e-09,\n         5.12665799e-09, -8.82927659e-09,  1.86075137e-08, -4.68368833e-09]))"
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "source": [
    "linear_reg = LinearRegression(\n",
    ")\n",
    "linear_reg.main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bita1e0ca745fc0402db26de9ef82f35b9c",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}